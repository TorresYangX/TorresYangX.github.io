<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xuan Yang</title>
  
  <meta name="author" content="Xuan Yang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 120 90%22><text y=%22.9em%22 font-size=%2295%22>üç™</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xuan Yang</name>
              </p>
              <p>I am a senior undergraduate student at the Southern University of Science and Technology, majoring in Computer Science and Technology. I have had the privilege of being advised by <a href="https://www.sustech.edu.cn/zh/faculties/songxuan.html">Prof. Xuan Song</a> during my undergraduate studies. From August 2023 to March 2024, I worked as a research assistant at Peking University under the supervision of <a href="https://urban.pkusz.edu.cn/info/1013/3002.html">Prof. Haoran Zhang</a>. Between June 2024 and October 2024, I served as a research intern at the University of Illinois Urbana-Champaign, where I was advised by <a href="https://aisecure.github.io/">Prof. Bo Li</a>.</p>
              <p> 
                My research interests focus on <b>Trustworthy Machine Learning</b>, with a particular emphasis on Large Language Models (LLMs). I am especially interested in enhancing their reliability and trustworthiness by integrating real-world knowledge and reasoning into the learning process. I am currently pursuing a Ph.D. in Computer Science and am enthusiastic about enhancing my scientific research ability and experience.
              </p>
              <p style="text-align:center">
                <a href="mailto:12112729@mail.sustech.edu.cn">Email</a> &nbsp/&nbsp
                <a href="data/CV_Xuan_Yang.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="data/Jiawei-bio.txt">Bio</a> &nbsp/&nbsp -->
                <!-- <a href="https://scholar.google.com/citations?hl=en&user=vCY9ZRcAAAAJ">Google Scholar</a> &nbsp/&nbsp -->
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/TorresYangX/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:35%;max-width:40%">
              <a href="images/avatar.png"><img style="width:80%;max-width:80%" alt="profile photo" src="images/avatar.png" class="hoverZoomLink"></a>
            </td>
          </tr>
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications and Preprints</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="samurai_stop()" onmouseover="samurai_start()">
            <td style="padding:20px;width:31%;vertical-align:middle">
              <div class="one">
                <img src='images/SafeAuto.png' width="260" height="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/18Zizw5SyPSmAh-ousJvil56c4bOBiy_A/view?usp=sharing">
                <papertitle>SafeAuto: Knowledge‚ÄëEnhanced Safe Autonomous Driving With Multimodal Foundation Models</papertitle>
              </a>
              <br>
              Jiawei Zhang, <b>Xuan Yang</b>, Taiqi Wang, Yu Yao, Aleksandr Petiushko, Bo Li.
              <br>
              <em>ICLR</em>, 2025
              <p>
              - We propose SafeAuto, a framework that enhances MLLMs for autonomous driving with three key contributions: a PDCE loss that maintains the autoregressive nature of MLLMs while mimicking MSE loss during training, the use of Markov Logic Networks (MLN) to encode domain knowledge and traffic rules, and a method for retrieving similar driving experiences using video data, control signals, and MLN-based environmental predicates.<br>
              <!-- <font color="red">SOTA Certified RMSE and  on ImageNet:</font> 77.2%, 63.2%, 53.0% under L2 radius 0.5, 1.0, 1.5, respectively. As a comparison, the current best results are 71.1%, 54.3%, and 38.1%. -->
              </p>
            </td>
          </tr>   

          <tr onmouseout="samurai_stop()" onmouseover="samurai_start()">
            <td style="padding:20px;width:31%;vertical-align:middle">
              <div class="one">
                <img src='images/NVAE.jpg' width="260" height="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1H0RHnnYekR_Df0w5sbE_QxFaxn35xKkP/view?usp=sharing">
                <papertitle>Reconstructing Trajectories with Transformer Variational AutoEncoder</papertitle>
              </a>
              <br>
              <b>Xuan Yang</b>, Dou Huang, Haoran Zhang, Jianan Xie, Yebei Gou, Xuan Song
              <br>
              <p>
              - We propose a transformer autoencoder model based on the Nonparametric Variational AutoEncoder (NVAE) to extract latent features from mobility trajectories. To reconstruct the original trajectory, we use KDTree to search for similar trajectories. Our model's effectiveness is demonstrated on the Geolife and Porto Taxi datasets, where it achieves superior performance compared to state-of-the-art methods in terms of trajectory reconstruction accuracy.<br>
              </p>
            </td>
          </tr>		
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Course Projects</heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr onmouseout="samurai_stop()" onmouseover="samurai_start()">
          <td style="padding:20px;width:31%;vertical-align:middle">
            <div class="one">
              <img src='images/TSDR.png' width="260" height="140">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/TorresYangX/Traffic-Sign-Detection-and-Recognition">
              <papertitle>Traffic Sign Detection and Recognition</papertitle>
            </a>
            <br>
            Technologies: YOLOv8, HSV, MSER
            <br>
            <p>
            - We enhance the recognition accuracy of YOLOv8 for traffic signs by 2% using HSV and MSER augmentation techniques.<br>
            <!-- <font color="red">SOTA Certified RMSE and  on ImageNet:</font> 77.2%, 63.2%, 53.0% under L2 radius 0.5, 1.0, 1.5, respectively. As a comparison, the current best results are 71.1%, 54.3%, and 38.1%. -->
            </p>
          </td>
        </tr>   

        <tr onmouseout="samurai_stop()" onmouseover="samurai_start()">
          <td style="padding:20px;width:31%;vertical-align:middle">
            <div class="one">
              <img src='images/poster_analyzer.png' width="260" height="160">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/TorresYangX/Poster-Analyzer">
              <papertitle>AI‚Äëbased Analysis of SustechLecturePosterAuthorship</papertitle>
            </a>
            <br>
            Technologies: paddleOCR, beautifulsoup, ChatGPT
            <br>
            <p>
            - We developed a software application with a graphical user interface (GUI) to automatically generate academic lecture abstracts using PaddleOCR, BeautifulSoup, and ChatGPT. This application has been successfully deployed on the SUSTech library server.<br>
            <!-- <font color="red">SOTA Certified RMSE and  on ImageNet:</font> 77.2%, 63.2%, 53.0% under L2 radius 0.5, 1.0, 1.5, respectively. As a comparison, the current best results are 71.1%, 54.3%, and 38.1%. -->
            </p>
          </td>
        </tr>   

        <tr onmouseout="samurai_stop()" onmouseover="samurai_start()">
          <td style="padding:20px;width:31%;vertical-align:middle">
            <div class="one">
              <img src='images/FileManager.png' width="260" height="140">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/TorresYangX/CS305-HTTP-File-Manager">
              <papertitle>HTTP File Manager</papertitle>
            </a>
            <br>
            Technologies: xxx
            <br>
            <p>
            - We construct a simple file manager server in Python based on characteristics of HTTP/1.1 that has ability to serve several clients with legitimate permissions to view, download, upload, delete files.<br>
            <!-- <font color="red">SOTA Certified RMSE and  on ImageNet:</font> 77.2%, 63.2%, 53.0% under L2 radius 0.5, 1.0, 1.5, respectively. As a comparison, the current best results are 71.1%, 54.3%, and 38.1%. -->
            </p>
          </td>
        </tr>  
        
        <tr onmouseout="samurai_stop()" onmouseover="samurai_start()">
          <td style="padding:20px;width:31%;vertical-align:middle">
            <div class="one">
              <img src='images/web.png' width="260" height="140">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/Haosonn/OOAD-Project-Frontend">
              <papertitle>SUSTech Graduate Student Dormitory Selection System</papertitle>
            </a>
            <br>
            Technologies: Vue3, Router, WebSocket, Axois, JPA
            <br>
            <p>
            - We developed a website to assist freshmen in choosing dormitories, utilizing Vue 3, JPA, and Axios. The website has been successfully deployed on the SUSTech server.<br>
            <!-- <font color="red">SOTA Certified RMSE and  on ImageNet:</font> 77.2%, 63.2%, 53.0% under L2 radius 0.5, 1.0, 1.5, respectively. As a comparison, the current best results are 71.1%, 54.3%, and 38.1%. -->
            </p>
          </td>
        </tr>   

        <tr onmouseout="samurai_stop()" onmouseover="samurai_start()">
          <td style="padding:20px;width:31%;vertical-align:middle">
            <div class="one">
              <img src='images/nus.png' width="260" height="140">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/TorresYangX/NUS-Real-Time-Graphic-Rendering">
              <papertitle>Real Time 3D Graphics Rendering</papertitle>
            </a>
            <br>
            Technologies: GLSL, OpenGL, Shadertoy
            <br>
            <p>
            - We implemented the Whitted Ray Tracing algorithm using GLSL on Shadertoy and successfully deployed it on the platform.<br>
            <!-- <font color="red">SOTA Certified RMSE and  on ImageNet:</font> 77.2%, 63.2%, 53.0% under L2 radius 0.5, 1.0, 1.5, respectively. As a comparison, the current best results are 71.1%, 54.3%, and 38.1%. -->
            </p>
          </td>
        </tr>   
        

        

      </a></td>
    </tr>
  </tbody></table>
</html>